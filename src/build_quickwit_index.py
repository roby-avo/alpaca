from __future__ import annotations

import argparse
import json
import sys
import time
from collections.abc import Iterator
from pathlib import Path
from typing import Any

from .common import (
    BOW_OUTPUT_PATH_ENV,
    QUICKWIT_INDEX_CONFIG_PATH_ENV,
    QUICKWIT_INDEX_ID_ENV,
    QUICKWIT_URL_ENV,
    ensure_existing_file,
    estimate_jsonl_record_total,
    finalize_tqdm_total,
    keep_tqdm_total_ahead,
    resolve_bow_output_path,
    resolve_quickwit_index_config_path,
    resolve_quickwit_index_id,
    resolve_quickwit_url,
    open_text_for_read,
    tqdm,
)
from .quickwit_client import QuickwitClient, QuickwitClientError


def parse_positive_int(raw: str) -> int:
    try:
        value = int(raw)
    except ValueError as exc:
        raise argparse.ArgumentTypeError("must be an integer") from exc

    if value <= 0:
        raise argparse.ArgumentTypeError("must be > 0")
    return value


def parse_non_negative_int(raw: str) -> int:
    try:
        value = int(raw)
    except ValueError as exc:
        raise argparse.ArgumentTypeError("must be an integer") from exc

    if value < 0:
        raise argparse.ArgumentTypeError("must be >= 0")
    return value


def parse_non_negative_float(raw: str) -> float:
    try:
        value = float(raw)
    except ValueError as exc:
        raise argparse.ArgumentTypeError("must be a number") from exc

    if value < 0:
        raise argparse.ArgumentTypeError("must be >= 0")
    return value


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Create/update a Quickwit index and ingest BOW JSONL documents "
            "for entity retrieval."
        )
    )
    parser.add_argument(
        "--quickwit-url",
        help=(
            f"Quickwit base URL (example: http://localhost:7280). "
            f"Overrides ${QUICKWIT_URL_ENV}."
        ),
    )
    parser.add_argument(
        "--index-id",
        help=f"Quickwit index ID. Overrides ${QUICKWIT_INDEX_ID_ENV}.",
    )
    parser.add_argument(
        "--index-config-path",
        help=(
            "Path to Quickwit index config JSON. "
            f"Overrides ${QUICKWIT_INDEX_CONFIG_PATH_ENV}."
        ),
    )
    parser.add_argument(
        "--bow-docs-path",
        help=(
            f"Path to BOW JSONL(.gz) docs generated by build_bow_docs.py. "
            f"Overrides ${BOW_OUTPUT_PATH_ENV}."
        ),
    )
    parser.add_argument(
        "--chunk-bytes",
        type=parse_positive_int,
        default=8_000_000,
        help="Max NDJSON payload bytes per ingest request (default: 8000000).",
    )
    parser.add_argument(
        "--ingest-limit",
        type=parse_non_negative_int,
        default=0,
        help="Limit docs ingested for smoke runs (0 = no limit).",
    )
    parser.add_argument(
        "--final-commit",
        choices=("auto", "wait_for", "force"),
        default="wait_for",
        help="Commit mode for final ingest chunk (default: wait_for).",
    )
    parser.add_argument(
        "--wait-timeout-seconds",
        type=parse_non_negative_float,
        default=120.0,
        help="How long to wait for Quickwit startup (default: 120).",
    )
    parser.add_argument(
        "--poll-interval-seconds",
        type=parse_non_negative_float,
        default=2.0,
        help="Polling interval while waiting for Quickwit (default: 2).",
    )
    parser.add_argument(
        "--http-timeout-seconds",
        type=parse_positive_int,
        default=120,
        help="HTTP timeout per Quickwit request (default: 120).",
    )
    return parser.parse_args()


def load_index_config(index_config_path: Path, index_id: str) -> dict[str, Any]:
    ensure_existing_file(
        index_config_path,
        "Quickwit index config",
        hint=(
            "Provide --index-config-path or set "
            f"${QUICKWIT_INDEX_CONFIG_PATH_ENV} to a valid JSON config file."
        ),
    )

    raw_text = index_config_path.read_text(encoding="utf-8")
    try:
        parsed = json.loads(raw_text)
    except json.JSONDecodeError as exc:
        raise ValueError(
            f"Quickwit index config at '{index_config_path}' is not valid JSON: {exc.msg}"
        ) from exc

    if not isinstance(parsed, dict):
        raise ValueError(f"Quickwit index config at '{index_config_path}' must be a JSON object.")

    parsed["index_id"] = index_id
    return parsed


def wait_for_quickwit(
    client: QuickwitClient,
    timeout_seconds: float,
    poll_interval_seconds: float,
) -> None:
    deadline = time.monotonic() + timeout_seconds
    while True:
        if client.is_healthy():
            return

        if time.monotonic() >= deadline:
            raise QuickwitClientError(
                f"Quickwit did not become healthy at {client.base_url} within {timeout_seconds:.1f}s"
            )

        time.sleep(max(0.2, poll_interval_seconds))


def _extract_index_ids(list_indexes_response: Any) -> set[str]:
    if not isinstance(list_indexes_response, list):
        return set()

    index_ids: set[str] = set()
    for entry in list_indexes_response:
        if not isinstance(entry, dict):
            continue

        index_id = entry.get("index_id")
        if isinstance(index_id, str) and index_id:
            index_ids.add(index_id)
            continue

        index_config = entry.get("index_config")
        if isinstance(index_config, dict):
            nested_index_id = index_config.get("index_id")
            if isinstance(nested_index_id, str) and nested_index_id:
                index_ids.add(nested_index_id)
                continue

        fallback_id = entry.get("id")
        if isinstance(fallback_id, str) and fallback_id:
            index_ids.add(fallback_id)
            continue

        index_uid = entry.get("index_uid")
        if isinstance(index_uid, str) and index_uid:
            parsed = index_uid.split(":", maxsplit=1)[0].strip()
            if parsed:
                index_ids.add(parsed)

    return index_ids


def wait_for_index(
    client: QuickwitClient,
    index_id: str,
    timeout_seconds: float,
    poll_interval_seconds: float,
) -> None:
    deadline = time.monotonic() + timeout_seconds
    while True:
        try:
            index_ids = _extract_index_ids(client.list_indexes())
        except QuickwitClientError:
            index_ids = set()

        if index_id in index_ids:
            return

        if time.monotonic() >= deadline:
            raise QuickwitClientError(
                f"Quickwit index '{index_id}' was not visible within {timeout_seconds:.1f}s"
            )

        time.sleep(max(0.2, poll_interval_seconds))


def iter_ndjson_chunks(
    docs_path: Path,
    max_chunk_bytes: int,
    ingest_limit: int,
) -> Iterator[tuple[str, int]]:
    emitted_docs = 0
    current_lines: list[str] = []
    current_bytes = 0

    with open_text_for_read(docs_path) as handle:
        for raw_line in handle:
            line = raw_line if raw_line.endswith("\n") else f"{raw_line}\n"
            if not line.strip():
                continue

            if ingest_limit > 0 and emitted_docs >= ingest_limit:
                break

            encoded = line.encode("utf-8")
            encoded_len = len(encoded)
            if encoded_len > max_chunk_bytes:
                raise ValueError(
                    f"Single JSONL line exceeds --chunk-bytes ({max_chunk_bytes}). "
                    "Increase chunk size or reduce document size."
                )

            if current_lines and (current_bytes + encoded_len > max_chunk_bytes):
                yield "".join(current_lines), len(current_lines)
                current_lines = []
                current_bytes = 0

            current_lines.append(line)
            current_bytes += encoded_len
            emitted_docs += 1

    if current_lines:
        yield "".join(current_lines), len(current_lines)


def ingest_all_chunks(
    client: QuickwitClient,
    index_id: str,
    docs_path: Path,
    chunk_bytes: int,
    ingest_limit: int,
    final_commit: str,
    ingest_retry_timeout_seconds: float,
    poll_interval_seconds: float,
) -> int:
    chunk_iter = iter_ndjson_chunks(docs_path, chunk_bytes, ingest_limit)
    current = next(chunk_iter, None)

    if current is None:
        return 0

    ingested_docs = 0
    progress_total = estimate_jsonl_record_total(
        docs_path,
        limit=ingest_limit if ingest_limit > 0 else None,
    )
    if progress_total is not None:
        print(f"Progress estimate: quickwit-ingest total~{progress_total} docs")
    with tqdm(total=progress_total, desc="quickwit-ingest", unit="doc") as progress:
        while current is not None:
            payload, doc_count = current
            next_chunk = next(chunk_iter, None)
            commit_mode = final_commit if next_chunk is None else "auto"
            _ingest_chunk_with_retry(
                client=client,
                index_id=index_id,
                ndjson_payload=payload,
                commit_mode=commit_mode,
                retry_timeout_seconds=ingest_retry_timeout_seconds,
                poll_interval_seconds=poll_interval_seconds,
            )
            ingested_docs += doc_count
            progress.update(doc_count)
            keep_tqdm_total_ahead(progress)
            current = next_chunk
        finalize_tqdm_total(progress)

    return ingested_docs


def _ingest_chunk_with_retry(
    client: QuickwitClient,
    index_id: str,
    ndjson_payload: str,
    commit_mode: str,
    retry_timeout_seconds: float,
    poll_interval_seconds: float,
) -> None:
    deadline = time.monotonic() + retry_timeout_seconds
    while True:
        try:
            client.ingest_ndjson(
                index_id=index_id,
                ndjson_payload=ndjson_payload,
                commit=commit_mode,
            )
            return
        except QuickwitClientError as exc:
            retryable = exc.status_code in {None, 404}
            if not retryable or time.monotonic() >= deadline:
                raise
            time.sleep(max(0.2, poll_interval_seconds))


def run(
    quickwit_url: str,
    index_id: str,
    index_config_path: Path,
    docs_path: Path,
    chunk_bytes: int,
    ingest_limit: int,
    final_commit: str,
    wait_timeout_seconds: float,
    poll_interval_seconds: float,
    http_timeout_seconds: float,
) -> int:
    ensure_existing_file(
        docs_path,
        "BOW docs JSONL",
        hint=(
            f"Run build_bow_docs.py first or pass --bow-docs-path / set ${BOW_OUTPUT_PATH_ENV}."
        ),
    )

    index_config = load_index_config(index_config_path, index_id)
    client = QuickwitClient(base_url=quickwit_url, timeout_seconds=http_timeout_seconds)

    wait_for_quickwit(client, wait_timeout_seconds, poll_interval_seconds)
    client.ensure_index(index_id=index_id, index_config=index_config)
    wait_for_index(client, index_id, wait_timeout_seconds, poll_interval_seconds)

    ingested_docs = ingest_all_chunks(
        client=client,
        index_id=index_id,
        docs_path=docs_path,
        chunk_bytes=chunk_bytes,
        ingest_limit=ingest_limit,
        final_commit=final_commit,
        ingest_retry_timeout_seconds=wait_timeout_seconds,
        poll_interval_seconds=poll_interval_seconds,
    )

    print(
        "Completed Quickwit indexing:",
        f"quickwit={quickwit_url}",
        f"index_id={index_id}",
        f"ingested={ingested_docs}",
        f"docs={docs_path}",
    )
    return 0


def main() -> int:
    args = parse_args()

    try:
        quickwit_url = resolve_quickwit_url(args.quickwit_url)
        index_id = resolve_quickwit_index_id(args.index_id)
        index_config_path = resolve_quickwit_index_config_path(args.index_config_path)
        docs_path = resolve_bow_output_path(args.bow_docs_path)

        return run(
            quickwit_url=quickwit_url,
            index_id=index_id,
            index_config_path=index_config_path,
            docs_path=docs_path,
            chunk_bytes=args.chunk_bytes,
            ingest_limit=args.ingest_limit,
            final_commit=args.final_commit,
            wait_timeout_seconds=args.wait_timeout_seconds,
            poll_interval_seconds=args.poll_interval_seconds,
            http_timeout_seconds=float(args.http_timeout_seconds),
        )
    except (FileNotFoundError, ValueError, QuickwitClientError) as exc:
        print(f"ERROR: {exc}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    raise SystemExit(main())
